{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f717ef-4cba-4300-b258-0b1c248cb873",
   "metadata": {},
   "source": [
    "# Document QA\n",
    "\n",
    "Deep Search allows users to interact with the documents using conversational AI, i.e. you interact with a virtual assistant which answer your questions using the information in the corpus.\n",
    "This works both on the public and private data libraries.\n",
    "\n",
    "In this example we demonstrate how achive the same interaction programmatically.\n",
    "\n",
    "\n",
    "### Access required\n",
    "\n",
    "The content of this notebook requires access to Deep Search capabilities which are not\n",
    "available on the public access system.\n",
    "\n",
    "[Contact us](https://ds4sd.github.io/) if you are interested in exploring\n",
    "the enterprise-level Deep Search capabilities.\n",
    "\n",
    "\n",
    "### GenAI Integration required\n",
    "\n",
    "When interacting with the virtual assistant, Deep Search requires a connection to a Generative AI API. Currently, we support connections to [watsonx.ai](https://www.ibm.com/products/watsonx-ai) or the IBM-internal GenAI platform BAM.\n",
    "\n",
    "Deep Search allows custom GenAI configurations for each project.\n",
    "In the following example you will require to work in a project which has such GenAI capabilities activated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256aef50-71a1-4278-9b22-17cb99a6566e",
   "metadata": {},
   "source": [
    "### Notebooks parameters\n",
    "\n",
    "The following block defines the parameters used to execute the notebook\n",
    "\n",
    "- `PROJ_KEY`: the Deep Search project to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b244bdd-1b52-41ff-b63e-9a203570d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_KEY = \"1234567890abcdefghijklmnopqrstvwyz123456\"  # For this examples we can use the Community project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5269060-bb5f-4fe3-9b64-547202db6714",
   "metadata": {},
   "source": [
    "### Import example dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d236ea0-db1c-4171-8e11-cdd0bad69d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard dependenices\n",
    "import pandas as pd\n",
    "\n",
    "# IPython utilities\n",
    "from IPython.display import display, Markdown, HTML, display_html\n",
    "\n",
    "# Import the deepsearch-toolkit\n",
    "import deepsearch as ds\n",
    "from deepsearch.cps.client.api import CpsApi\n",
    "from deepsearch.cps.apis import public as sw_client\n",
    "from deepsearch.cps.client.components.elastic import ElasticDataCollectionSource\n",
    "from deepsearch.cps.client.queries import Query\n",
    "from deepsearch.cps.queries import DataQuery, DocumentQuestionQuery\n",
    "from deepsearch.cps.client.components.queries import RunQueryError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293c249b-6018-46f2-b4d8-795f994d4729",
   "metadata": {},
   "source": [
    "### Connect to Deep Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c108432-a285-4c7b-a996-008ac3ff3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = CpsApi.from_env(profile_name=\"sds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cde869-46d1-4833-8eb3-2381b5e5fb68",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a0c34-4217-41e0-8987-e303f8b4e538",
   "metadata": {},
   "source": [
    "## Interact with a RedHat Manual\n",
    "\n",
    "In the following blocks we will\n",
    "1. Search for an interesting document in our collection of RedHat manuals\n",
    "2. Load the document into the DocumentQA engine\n",
    "3. Ask questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b38875e-f39c-4dd5-9d42-3ffca5d0bdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching all data. Total is 1 records.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>DocHash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product Documentation for OpenShift Container ...</td>\n",
       "      <td>6e017dcb29a0348e1f6e5554bb547b979e7e47256d9dc2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Product Documentation for OpenShift Container ...   \n",
       "\n",
       "                                             DocHash  \n",
       "0  6e017dcb29a0348e1f6e5554bb547b979e7e47256d9dc2...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_collection = \"redhat\"\n",
    "data_instance = \"default\"\n",
    "search_query = \"\\\"OpenShift Container Platform 4.12 Getting started\\\"\"\n",
    "\n",
    "\n",
    "# Prepare the data query\n",
    "collection_coords = ElasticDataCollectionSource(elastic_id=data_instance, index_key=data_collection)\n",
    "query = DataQuery(\n",
    "    search_query,  # The search query to be executed\n",
    "    source=[\"description.title\", \"file-info.document-hash\"],  # Which fields of documents we want to fetch\n",
    "    coordinates=collection_coords,  # The data collection to be queries\n",
    ")\n",
    "\n",
    "\n",
    "# Query Deep Search for the documents matching the query\n",
    "results = []\n",
    "query_results = api.queries.run(query)\n",
    "for row in query_results.outputs[\"data_outputs\"]:\n",
    "        # Add row to results table\n",
    "        results.append({\n",
    "            \"Title\": row[\"_source\"][\"description\"][\"title\"],\n",
    "            \"DocHash\": row[\"_source\"][\"file-info\"][\"document-hash\"],\n",
    "        })\n",
    "\n",
    "print(f'Finished fetching all data. Total is {len(results)} records.')\n",
    "\n",
    "# Visualize the table with all results\n",
    "df = pd.json_normalize(results)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f39c577-80d3-4f62-9e48-56969cafe3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we launch the ingestion of the document for DocumentQA\n",
    "\n",
    "doc_hash = results[0][\"DocHash\"]\n",
    "\n",
    "ingest_api = sw_client.DocumentInspectionApi(api.client.swagger_client)\n",
    "\n",
    "task = api.documents.ingest_documentqa(PROJ_KEY, collection_coords, doc_hash)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67099ce5-bdf9-4d83-a672-692d80f64944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we wait for the ingestion task to finish\n",
    "\n",
    "api.tasks.wait_for(task.proj_key, task.task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee573e76-98ea-43ce-a2ba-a81f64b3adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we query the document for the question\n",
    "\n",
    "question = \"Can I use the Kubernetes command line utilities with an OpenShift cluster?\"\n",
    "\n",
    "question_query = DocumentQuestionQuery(\n",
    "    question=question,\n",
    "    document_hash=doc_hash,\n",
    "    project=PROJ_KEY,\n",
    ")\n",
    "question_results = api.queries.run(question_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89d95a17-1569-4c90-a983-8ca437b7569d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Question: Can I use the Kubernetes command line utilities with an OpenShift cluster?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Answer: OpenShift Container Platform CLI tool (oc) is compatible with kubectl."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The provenance of the answer can be inspected on the [source document](https://sds.app.accelerate.science/projects/1234567890abcdefghijklmnopqrstvwyz123456/library/public?search=JTdCJTIyY29sbGVjdGlvbnMlMjIlM0ElNUIlMjJyZWRoYXQlMjIlNUQlMkMlMjJ0eXBlJTIyJTNBJTIyRG9jdW1lbnQlMjIlMkMlMjJleHByZXNzaW9uJTIyJTNBJTIyZmlsZS1pbmZvLmRvY3VtZW50LWhhc2glM0ElMjAlNUMlMjI2ZTAxN2RjYjI5YTAzNDhlMWY2ZTU1NTRiYjU0N2I5NzllN2U0NzI1NmQ5ZGMyZjBlZGY2Y2I5NDEwYWE1NzU2JTVDJTIyJTIyJTJDJTIyZmlsdGVycyUyMiUzQSU1QiU1RCUyQyUyMnNlbGVjdCUyMiUzQSU1QiUyMl9uYW1lJTIyJTJDJTIyZGVzY3JpcHRpb24uY29sbGVjdGlvbiUyMiUyQyUyMnByb3YlMjIlMkMlMjJkZXNjcmlwdGlvbi50aXRsZSUyMiUyQyUyMmRlc2NyaXB0aW9uLnB1YmxpY2F0aW9uX2RhdGUlMjIlMkMlMjJkZXNjcmlwdGlvbi51cmxfcmVmcyUyMiU1RCUyQyUyMml0ZW1JbmRleCUyMiUzQTAlMkMlMjJwYWdlU2l6ZSUyMiUzQTEwJTJDJTIyc2VhcmNoQWZ0ZXJIaXN0b3J5JTIyJTNBJTVCJTVEJTJDJTIydmlld1R5cGUlMjIlM0ElMjJzbmlwcGV0cyUyMiUyQyUyMnJlY29yZFNlbGVjdGlvbiUyMiUzQSU3QiUyMnJlY29yZCUyMiUzQSU3QiUyMmlkJTIyJTNBJTIyNmUwMTdkY2IyOWEwMzQ4ZTFmNmU1NTU0YmI1NDdiOTc5ZTdlNDcyNTZkOWRjMmYwZWRmNmNiOTQxMGFhNTc1NiUyMiU3RCUyQyUyMml0ZW1JbmRleCUyMiUzQTcwJTdEJTdE)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the answer to the question\n",
    "\n",
    "## Unpack the answer\n",
    "answer = question_results.outputs[\"answer\"]\n",
    "\n",
    "## Compute URL to the document in the Deep Search UI\n",
    "doc_url = api.documents.generate_url(\n",
    "    document_hash=doc_hash,\n",
    "    data_source=collection_coords,\n",
    "    item_index=question_results.outputs[\"provenance\"][0][\"entity_counter\"],\n",
    ")\n",
    "\n",
    "## Display results\n",
    "display(Markdown(f\"Question: {question}\"))\n",
    "display(Markdown(f\"Answer: {answer}\"))\n",
    "display(Markdown(f\"The provenance of the answer can be inspected on the [source document]({doc_url}).\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd9f5d-ebf6-4ba0-8318-23adac541c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
