{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d96e78",
   "metadata": {},
   "source": [
    "# Material Science on Documents - Quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edb626f",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "The [Deep Search Toolkit](https://ds4sd.github.io/deepsearch-toolkit/) allows document conversion with the following few lines of code. It's that simple! For more info or step-by-step guide:\n",
    "- Visit https://ds4sd.github.io/deepsearch-toolkit/guide/convert_doc/\n",
    "- Follow this example notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f9c441",
   "metadata": {},
   "source": [
    "### Set notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01a4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsnotebooks.settings import ProjectNotebookSettings\n",
    "\n",
    "# notebook settings auto-loaded from .env / env vars\n",
    "notebook_settings = ProjectNotebookSettings()\n",
    "\n",
    "PROFILE_NAME = notebook_settings.profile  # the profile to use\n",
    "PROJ_KEY = notebook_settings.proj_key  # the project to use\n",
    "\n",
    "# default project_key = 1234567890abcdefghijklmnopqrstvwyz123456"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239dc0f1",
   "metadata": {},
   "source": [
    "### Import example dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502cdef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T12:14:25.377422Z",
     "start_time": "2022-08-02T12:14:25.152485Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import deepsearch as ds\n",
    "\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from deepsearch.documents.core.export import export_to_markdown\n",
    "from IPython.display import display, Markdown, HTML, display_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4dcda",
   "metadata": {},
   "source": [
    "### Connect to Deep Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f44fbf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = ds.CpsApi.from_env(profile_name=PROFILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1200c5-1138-4491-bc33-3b2d5aabe949",
   "metadata": {},
   "source": [
    "## Convert Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec83eb0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T12:14:49.216045Z",
     "start_time": "2022-08-02T12:14:25.380757Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting input:     :   0%|\u001b[38;2;15;98;254m                              \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[38;2;15;98;254m\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santana/Documents/dev/deepsearch-examples/venv/lib/python3.10/site-packages/pydantic/main.py:426: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `list[str]` but got `_LiteralGenericAlias` with value `typing.Literal['ApiServer...lsHttpSource', 'object']` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "Submitting input:     : 100%|\u001b[38;2;15;98;254m██████████████████████████████\u001b[0m| 1/1 [00:02<00:00,  2.15s/it]\u001b[38;2;15;98;254m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_pages': 11, 'processed_pages': 11, 'truncated_pages': 0}\n"
     ]
    }
   ],
   "source": [
    "output_dir = Path(\"./converted_docs\")\n",
    "\n",
    "fname = \"20140197356.pdf\"\n",
    "\n",
    "documents = ds.convert_documents(\n",
    "    api=api,\n",
    "    proj_key=PROJ_KEY,\n",
    "    source_path=f\"../../data/samples/{fname}\",\n",
    "    progress_bar=True,\n",
    ")\n",
    "documents.download_all(result_dir=output_dir)\n",
    "info = documents.generate_report(result_dir=output_dir)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "382c4869-cca9-43fc-8052-c0ab7e9c175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group output files and visualize the output\n",
    "md_files = list(output_dir.glob(\"*.md\"))\n",
    "json_files = list(output_dir.glob(\"*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f7678-b650-484b-a994-150d0c4ec3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display last document\n",
    "# display(Markdown(md_files[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784c8a9-4b96-4385-a04e-40ddbf6c613f",
   "metadata": {},
   "source": [
    "## Find materials in a local PDF Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb458eb7-4c19-403f-a615-270c38542d20",
   "metadata": {},
   "source": [
    "### load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9099530a-1912-4651-9a40-76c4f4cf22af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> already downloaded part-of-speech\n",
      " -> already downloaded reference\n",
      " -> already downloaded material\n",
      " -> already downloaded language\n",
      " -> already downloaded name\n",
      " -> already downloaded semantic\n",
      " -> already downloaded geoloc\n"
     ]
    }
   ],
   "source": [
    "from deepsearch_glm.utils.load_pretrained_models import load_pretrained_nlp_models\n",
    "\n",
    "from deepsearch_glm.nlp_utils import (\n",
    "    extract_references_from_doc,\n",
    "    init_nlp_model,\n",
    "    list_nlp_model_configs,\n",
    ")\n",
    "\n",
    "from deepsearch_glm.glm_utils import (\n",
    "    create_glm_config_from_docs,\n",
    "    create_glm_dir,\n",
    "    create_glm_from_docs,\n",
    "    expand_terms,\n",
    "    load_glm,\n",
    "    read_edges_in_dataframe,\n",
    "    read_nodes_in_dataframe,\n",
    "    show_query_result,\n",
    ")\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "models = load_pretrained_nlp_models(verbose=True, force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b574c77b-58a5-4259-b8e9-03ce7129c3bf",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c995060-aee3-4b6c-ba8b-dce6288e44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifile = json_files[-1]\n",
    "\n",
    "with open(ifile) as fr:\n",
    "    doc = json.load(fr)\n",
    "\n",
    "model = init_nlp_model(\"language;term;material\")\n",
    "model.set_loglevel(\"INFO\")\n",
    "\n",
    "res = model.apply_on_doc(doc)\n",
    "\n",
    "insts = pd.DataFrame(res[\"instances\"][\"data\"], columns=res[\"instances\"][\"headers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01771757-70c3-44cb-824c-1fd9b716a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          type           subtype                                      name   subj_path\n",
      "32    material  complex_chemical                          - (21) Appl. No.   #/texts/4\n",
      "39    material  complex_chemical                                    - (22)   #/texts/6\n",
      "1095  material  complex_chemical                          2-methylpropyl).  #/texts/57\n",
      "1170  material  complex_chemical    2,4,7-trimethyloctadec-5-yne-4, 7-diol  #/texts/58\n",
      "1213  material  complex_chemical  2,5,8,11-tetramethyldodec-6-yne-5,8-diol  #/texts/58\n",
      "1666  material  complex_chemical                          1-naphthoic acid  #/texts/67\n",
      "1670  material  complex_chemical                          2-naphthoic acid  #/texts/67\n",
      "1713  material  complex_chemical                   1,2,3,4-butanetetracar›  #/texts/67\n"
     ]
    }
   ],
   "source": [
    "# print(insts.columns)\n",
    "\n",
    "materials = insts[\n",
    "    (insts[\"type\"] == \"material\") & (insts[\"subtype\"] == \"complex_chemical\")\n",
    "][[\"type\", \"subtype\", \"name\", \"subj_path\"]]\n",
    "print(materials.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f126e-1007-42db-9b9b-7768ea3c0c80",
   "metadata": {},
   "source": [
    "## Extracting materials from Document collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b78cb3e-25cb-4ab7-8533-e839623bb52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Num entries</th>\n",
       "      <th>Date</th>\n",
       "      <th>Coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAI</td>\n",
       "      <td>Document</td>\n",
       "      <td>16.02K</td>\n",
       "      <td>2023-08-29</td>\n",
       "      <td>default/aaai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACL Anthology</td>\n",
       "      <td>Document</td>\n",
       "      <td>55.28K</td>\n",
       "      <td>2023-08-22</td>\n",
       "      <td>default/acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annual Reports</td>\n",
       "      <td>Document</td>\n",
       "      <td>107.38K</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>default/annual-report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arXiv abstracts</td>\n",
       "      <td>Document</td>\n",
       "      <td>2.48M</td>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>default/arxiv-abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arXiv category taxonomy</td>\n",
       "      <td>Record</td>\n",
       "      <td>155</td>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>default/arxiv-category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arXiv full documents</td>\n",
       "      <td>Document</td>\n",
       "      <td>2.29M</td>\n",
       "      <td>2023-10-29</td>\n",
       "      <td>default/arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BioRxiv</td>\n",
       "      <td>Document</td>\n",
       "      <td>357.76K</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>default/biorxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brenda</td>\n",
       "      <td>Record</td>\n",
       "      <td>7.12K</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>default/brenda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>Record</td>\n",
       "      <td>2.42M</td>\n",
       "      <td>2024-04-26</td>\n",
       "      <td>default/chembl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ChEMBL (DEPRECATED)</td>\n",
       "      <td>Record</td>\n",
       "      <td>2.11M</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>default/chembl-deprecated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name      Type Num entries        Date  \\\n",
       "0                     AAAI  Document      16.02K  2023-08-29   \n",
       "1            ACL Anthology  Document      55.28K  2023-08-22   \n",
       "2           Annual Reports  Document     107.38K  2024-04-15   \n",
       "3          arXiv abstracts  Document       2.48M  2024-05-22   \n",
       "4  arXiv category taxonomy    Record         155  2024-05-22   \n",
       "5     arXiv full documents  Document       2.29M  2023-10-29   \n",
       "6                  BioRxiv  Document     357.76K  2023-11-09   \n",
       "7                   Brenda    Record       7.12K  2023-01-03   \n",
       "8                   ChEMBL    Record       2.42M  2024-04-26   \n",
       "9      ChEMBL (DEPRECATED)    Record       2.11M  2023-01-03   \n",
       "\n",
       "                      Coords  \n",
       "0               default/aaai  \n",
       "1                default/acl  \n",
       "2      default/annual-report  \n",
       "3     default/arxiv-abstract  \n",
       "4     default/arxiv-category  \n",
       "5              default/arxiv  \n",
       "6            default/biorxiv  \n",
       "7             default/brenda  \n",
       "8             default/chembl  \n",
       "9  default/chembl-deprecated  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numerize.numerize import numerize\n",
    "from datetime import datetime\n",
    "\n",
    "# Fetch list of all data collections\n",
    "collections = api.elastic.list()\n",
    "collections.sort(key=lambda c: c.name.lower())\n",
    "\n",
    "# Visualize summary table\n",
    "results = [\n",
    "    {\n",
    "        \"Name\": c.name,\n",
    "        \"Type\": c.metadata.type,\n",
    "        \"Num entries\": numerize(c.documents),\n",
    "        \"Date\": datetime.fromisoformat(c.metadata.created).strftime(\"%Y-%m-%d\"),\n",
    "        \"Coords\": f\"{c.source.elastic_id}/{c.source.index_key}\",\n",
    "    }\n",
    "    for c in collections\n",
    "]\n",
    "display(pd.DataFrame(results[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5394460-3427-4a89-a6e3-d655b28b0412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-found documents:  RunQueryResult(outputs={'data_outputs': [], 'data_count': 2, 'data_aggs': {'deepsearch_total_size': {'value': 780743.0}}}, next_pages={}, timings=RunQueryResult.QueryTimings(overall=3.0525007601827383, tasks={'0_ElasticQuery': RunQueryResult.QueryTimings.TaskTimings(overall=3.052005048841238, details={})}))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  1.56it/s]                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching all data. Total is 2 records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "from deepsearch.cps.client.components.elastic import ElasticDataCollectionSource\n",
    "from deepsearch.cps.queries import DataQuery\n",
    "\n",
    "\n",
    "# Input query\n",
    "search_query = '\"SUBSTITUTED 6-PHENYLNICOTINIC ACIDS AND THEIR USE\"'\n",
    "data_collection = ElasticDataCollectionSource(\n",
    "    elastic_id=\"default\", index_key=\"patent-uspto\"\n",
    ")\n",
    "page_size = 50\n",
    "\n",
    "# Prepare the data query\n",
    "query = DataQuery(\n",
    "    search_query,  # The search query to be executed\n",
    "    # source=[\"description.title\", \"description.authors\", \"identifiers\"], # Which fields of documents we want to fetch\n",
    "    limit=page_size,  # The size of each request page\n",
    "    coordinates=data_collection,  # The data collection to be queries\n",
    ")\n",
    "\n",
    "\n",
    "# [Optional] Compute the number of total results matched. This can be used to monitor the pagination progress.\n",
    "count_query = deepcopy(query)\n",
    "count_query.paginated_task.parameters[\"limit\"] = 0\n",
    "count_results = api.queries.run(count_query)\n",
    "expected_total = count_results.outputs[\"data_count\"]\n",
    "expected_pages = (\n",
    "    expected_total + page_size - 1\n",
    ") // page_size  # this is simply a ceiling formula\n",
    "\n",
    "print(f\"#-found documents: \", count_results)\n",
    "\n",
    "# Iterate through all results by fetching `page_size` results at the same time\n",
    "documents = []\n",
    "cursor = api.queries.run_paginated_query(query)\n",
    "for result_page in tqdm(cursor, total=expected_pages):\n",
    "    # Iterate through the results of a single page, and add to the total list\n",
    "    for row in result_page.outputs[\"data_outputs\"]:\n",
    "        documents.append(row[\"_source\"])\n",
    "\n",
    "print(f\"Finished fetching all data. Total is {len(documents)} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717419b-6d96-4848-bbbf-3d4149406872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "# Create a TextWrapper object\n",
    "wrapper = textwrap.TextWrapper(width=100)  # Set the desired width\n",
    "\n",
    "model = init_nlp_model(\"language;term;material\")\n",
    "model.set_loglevel(\"INFO\")\n",
    "\n",
    "max_items = 5\n",
    "\n",
    "for doc in documents:\n",
    "\n",
    "    dname = doc[\"file-info\"][\"filename\"]\n",
    "\n",
    "    for i, item in enumerate(doc[\"main-text\"]):\n",
    "\n",
    "        if \"text\" not in item:\n",
    "            continue\n",
    "\n",
    "        if i > max_items:\n",
    "            break\n",
    "\n",
    "        res = model.apply_on_text(item[\"text\"])\n",
    "\n",
    "        insts = pd.DataFrame(\n",
    "            res[\"instances\"][\"data\"], columns=res[\"instances\"][\"headers\"]\n",
    "        )\n",
    "\n",
    "        materials = insts[insts[\"type\"] == \"material\"][\n",
    "            [\"type\", \"subtype\", \"name\", \"subj_path\"]\n",
    "        ]\n",
    "\n",
    "        if len(materials) > 0:\n",
    "            lines = wrapper.wrap(item[\"text\"])\n",
    "            print(f\"\\n {dname}: text-{i}\\n\")\n",
    "            print(\"\\n\".join(lines), \"\\n\")\n",
    "            print(materials.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05280444-d67c-4828-bfc2-bb3f4bc8698e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
